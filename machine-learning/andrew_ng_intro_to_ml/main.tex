\section{Supervised and Unsupervised Learning}

\subsection{Supervised Learning1}
Supervised learning is a type of machine learning algorithm that uses a known dataset (called the training dataset) to make predictions. The training dataset includes input data and output data. The key of supervised learning is that you give your learning algorithm examples to learn from that include the "right answers", in other words the correct label \textbf{y} for the input \textbf{x}.
It learns by seeing correct pairs of inputs and outputs.  The goal is that eventually the algorithm will only be provided with the input-value(x) and it has to predict the output-value/label(y).
Examples: \\ \\ \\

\begin{align*}
  \scalebox{1.3}{
    \begin{tabular}{|c|c|c|}
      \hline
      Input(x)          & Output(y)              & Application         \\
      \hline
      email             & spam?(0/1)             & spam filtering      \\
      \hline
      audio             & text transcript        & speech recognition  \\
      \hline
      English           & Spanish                & machine translation \\
      \hline
      ad,user,info      & click?(0/1)            & online advertising  \\
      \hline
      image, radar info & position of other cars & self-driving car    \\
      \hline
      image of a phone  & defect?(0/1)           & visual inspection   \\
      \hline
    \end{tabular}}
\end{align*}

In all of these applications you first train your model on data where you know the correct output. Then you use that model to make predictions on new data. \\

\subsubsection*{Regression: Housing Price Prediction}
Regression is a type of supervised learning algorithm that tries to predict a continuous output variable. In other words, it is used to predict a number. For example, predicting the price of a house in dollars is a regression problem whereas predicting whether a tumor is malignant or benign is a classification problem. \\
In other words, Regression is a type of algorithm that tries to predict a continuous output variable.

\subsubsection*{Classification: Breast Cancer Prediction}
Say that you are trying to create a model that predicts whether or not a tumor is malignant or benign. In classification problems, the output variable is a category (such as "malignant" or "benign"). What we are trying to do is map input variables to discrete categories, we are classifying the input values into categories and trying to predict from the two possible output. Here we have a number of possible categories or outputs that our algorithm can predict. Whereas with regression we are trying to predict a continuous number.
To summarise, Classification is a type of algorithm that tries to predict a discrete category, that doesn't necessarily have to be a number. Also in classification we are predicting a small set of possible outputs, so we are given our "options" in regards of what can our output be.
By extension obviously, we can have two or more inputs, in this case we can think of inputs as a "context" dataset that is provided to us, such as the tumor size, or the patient's age, sex, etc... The more context we provide the more accurate our prediction will be.
What we often do is represent our data-set in a function for example and our algorithm would try to identify some form of pattern in the data-set.

\subsection{Summary of Supervised Learning}
In summary supervised learning is when we are given a data-set and we are told what our correct output should be. We are given the "right answers" and we are trying to learn from that data-set to be able to predict the correct output for new data without the need of the input.
We have looked at two categories of supervised learning, regression and classification. In regression we are trying to predict a continuous number, and in classification we are trying to predict a discrete category.


\subsection{Unsupervised Learning}

Previously, in our classification problem what we have looked at is a supervised learning problem. We have a data-set and we are given the correct output(y) for each example. In unsupervised learning we are given a data-set but we are \textbf{not} given any labels or output value(y). Say you were given with the tumor size and the patient's age and any other context, however you don't know whether the tumor is malignant or benign. You are not given any labels or output value.
Our job here is not to predict whether the tumor is malignant or benign, but rather to find some structure in the data-set. In other words find something interesting in the unlabeled data-set.
The reason why it is called unsupervised is because we are not supervising the algorithm, we are not telling it what the correct answer is, we are just giving it the data and asking it to find some structure in the data.
So it might identify that the data can be divided into number of sections, or it might find some form of patterns between the patient's age and their tumor size, or any other contextual prediction.
Essentially it tries to place the data into different clusters, clustering is a type of unsupervised learning, where we are trying to find some structure in the data. For example clustering is used in google news.
What google news does is every day it goes through all the news articles that are published and it tries to group them into different clusters, so that it can show you the different clusters of news articles and you can choose which cluster you are interested in.

Another type of unsupervised learning is anomaly detection where we are trying to find some abnormal behavior in the data. For example, if we have a data-set of credit card transactions and we are trying to find some unusual behavior in the data-set, such as unusual credit card transactions.
Another example is in manufacturing, where we are trying to find some unusual behavior in the manufacturing process, such as unusual defects in the product.
We also have dimensionality reduction where we are trying to take a data-set with a large number of features and reduce the number of features to a smaller number. For example, if we have a data-set with a large number of features, we might want to reduce the number of features to a smaller number so that we can visualize the data more easily.

\subsection{Linear Regression: House sizes and prices}
In this example let's imagine that we are given with a data-set about house prices and their sizes. We are given the size of the house in square feet and the price of the house in dollars. We are given a number of examples of houses and their prices. We are trying to predict the price of a new house given its size.
This is a perfect example of a linear regression model where we would first train our model on the data-set and showing the "right answers" and then we can use that model to predict the price of a new house given its size.

A data-set that is used to train a model is called a training set. The sizes of the house can be represented with x as for example if we  have a house that is 1000 square feet, we can represent that with x = 1000. The price of the house can be represented with y, so if the price of the house is 200,000 dollars, we can represent that with y = 200,000.

We call x as the "input" variable or feature, and refer to y as the "output" variable or target.

We can represent as a single training example by $$(x,y)$$ where x is the input and y is the output.
Our $i$th training example where I would represent a specific row from the training set would look like this: $(x^{(i)},y^{(i)})$.

Note that this doesn't mean that we are taking x and y to the power of i, but rather that we are taking the i'th training example from the training set.

So for example one example would look like this $$ (x^{(1)}, y^{(1)})=(2104,400) $$

Also as mentioned $$x^{(2)}\neq x^2$$

\subsection{Process of a Supervised training}
Supervised learning algorithm will input a dataset and then what exactly does it do and what does it output?
Recall that a training set in supervised learning includes both the input features, such as the size of the house and also the output targets, such as the price of the house. The output targets are the right answers to the model we'll learn from.
To train the model, you feed the training set, both the input features and the output targets to your learning algorithm. Then your supervised learning algorithm will produce a function which we can call as $f$ that maps from x's to y's.
As every function this function will take an input x and then output a y which we can also call y-hat $\hat{y}$. So for example if we have a house that is 1000 square feet, we can input that into our function and it will output a price for that house.
y-hat in machine learning is the predicted output.
The function $f$ is called the "model". When we see only $y$ that is the actual output, when we see $\hat{y}$ that is the \textbf{predicted} output.
When designing the learning algorithm the question is that how do we choose the function $f$? What is the math formula that we are going to use?
Inspired by the \textbf{slope-intercept form} $y=mx+b$ where $m$ is the slope and $b$ is the y-intercept, we can use the following formula for our function $f$:
$$ f_{w,b}(x) = wx + b $$
For now just note that both $w$ and $b$ are real numbers and will determine the prediction $\hat{y}$
Alternatively, we don't always have to include $w$ and $b$ we can simply just write $f(x)$ and it would be the same.
We can represent the training set on a graph where our goal is to find the best fitting line using our function $f$.
We are using that function for future predictions, this process is what we call \textbf{Linear Regression with one variable} because we only have $x$ as the input which is the size of the house.
Now go through the model representation

\subsection{Cost Function}
The cost function will tell us how well the model is doing so that we can improve it and make sure that it's going to get better over time.
Recall that we have introduced our model: $$ f_{w,b}(x) = wx + b $$ and just to add a bit more terminology to it, we can call $w$ as the weights and $b$ as the bias.
Again this is what we call the slope-intercept form of a line, where $w$ is the slope and $b$ is the y-intercept.
For example if we were to have two points on a graph, let's say that we'd have the points (1,3) and (2,5) and we want to find the line that best fits these two points. We can use the slope-intercept form of a line to find the best fitting line.
First we have to find the slope, which is the change in y over the change in x, so we can calculate the slope as follows:
$$ m=\frac{\Delta x}{\Delta y}=\frac{y_2-y_1}{x_2-x_1}={\frac{5-3}{2-1}}=2 $$
Now that we have the slope we can find the y-intercept by using the following formula:
We can substitute the slope and one of the points into the formula to find the y-intercept:
$$ 3=2+b $$
$$ b=1 $$
So now we have the slope and the y-intercept, we can write the equation of the line as follows:
$$ y=2x+1 $$
Now this equation is the equation of the line that best fits the two points. We can plot the line on the graph and we can see that it fits the two points perfectly.
Obviously this was very easy and we also assumed that the line will go through these points, however this will not likely be the case in real life.
In real life we will have a lot more points and we will have to find the line that best fits all of these points. In order to do so we will have to use a cost function.
A cost function is a measure of how well a machine learning model performs by quantifying the difference between predicted and actual outputs.
In other words it will compute the difference between: $\hat{y}$ and $y$ as $\hat{y}-y$.
This difference is called the error, and we can also call it the loss.
We can also square the error to make sure that it is positive, so we can write the error as follows:
\begin{align*}
  \scalebox{1.3}{$
    \sum_{i=0}^{m}\ (\hat{y}^{(i)}-y^{(i)})^2
  $}
\end{align*}
This case $m$ is the number of training examples, so we are summing over all of the training examples.
The problem here is that the more training examples we have, the larger the error will be. So we will have to divide the error by the number of training examples in order to avoid this huge numbers, so we can write the error as follows:
\begin{align*}
  \scalebox{1.3}{$
    \frac{1}{m}\sum_{i=0}^{m}\ (\hat{y}^{(i)}-y^{(i)})^2
  $}
\end{align*}

By convention machine learning people used to divide by $2m$, and also we can refer to the cost function as $J_(w,b)$ so our overall cost function will look like this:
\begin{align*}
  \scalebox{1.3}{$
    J_{(w,b)}=\frac{1}{2m}\sum_{i=0}^{m}\ (\hat{y}^{(i)}-y^{(i)})^2
  $}
\end{align*}

This is what we call the squared error cost function that is being used most commonly.

Now make sure to be aware of this:
\begin{align*}
  \scalebox{1.3}{$
    J_{(w,b)}=\frac{1}{2m}\sum_{i=0}^{m}\ (f_w,b(x^{(i)})-y^{(i)})^2
  $}
\end{align*}

\subsection{More deeply about cost function}
We will use one example and actually get to see how the cost function can be used to find the best fitting line.
Now let's recap what we have so far.
\begin{enumerate}
  \item \textbf{model:} We have our \textbf{model} which is represented with the slope-interecept function: $f_w,b(x)=wx+b$ and depending on what values we choose for the slope $w$ and the y-interecept $b$ we are getting a line.
  \item  \textbf{parameters:} The model's parameters will $w$ and $b$, again our goal is to find the best values for $w$ $b$ to get the best fitting lines.
  \item \textbf{cost function:} Now in order to measure how good the values for $w$ and $b$ are we are using our cost function which we have constructed before: $$ J_{(w,b)}=\frac{1}{2m}\sum_{i=0}^{m}\ (f_w,b(x^{(i)})-y^{(i)})^2 $$
        We are taking the difference between the predicted value and the actual value for $y$, so we are trying to reduce the value of $J$
  \item \textbf{goal: } So we can say that our goal is to: $$ minimize J(w,b)$$
\end{enumerate}

Now let's see an example of how the cost function and the model would work.
For simplicity we can get rid of the y-intercept $b$ meaning that our graphs will pass through the origin.

\begin{align*}
  \includegraphics[width=1.2\textwidth]{machine-learning/andrew_ng_intro_to_ml/cost_function.png}
\end{align*}

As you can see here we have started off by plotting 3 points in which were: $(1,1)$ $(2,2)$ and $(3,3)$
Then what we wanted to do is test out our const function. We have identified the slope $w$ to be $1$ which ended up passing through all of the points perfectly.
Since this line passes through all of the points we expected $J(x)$ to be 0. \\
Notice that when evaluating $J$ we are passing in the slope $w$ as the parameter.
As you can see we have evaluated $J(w)$ and as we expected it turned out to be 0.
In the other graph we can see that if we visualise the our slopes and const function solutions in a graph where we have the axis $w$ and $J(x)$.
We can see that when $w=1$ $J(x)=0$.
The reason why the cost function is zero, is because we have identified the slope of the function successfully which resulted the \textbf{perfectly} fitting line.
We can validate our slope calculation by this formula: $$ m=\frac{\Delta y}{\Delta x}=\frac{1}{1}=1 $$ In short the slope is just a fraction of the change in y over the change in x.

Now let's try a different value of $w$ and pretend that we wouldn't know how to calculate the slope of this line.
If $w=0.5$ then obviously it's not going to fit the points well, therefore we expect $J(x)$ to be more than 0.

\begin{align*}
  \includegraphics[width=1.2\textwidth]{machine-learning/andrew_ng_intro_to_ml/cost_function_0.5.png}
\end{align*}

We can see here that the line doesn't fit well to the points, therefore when calculating the difference between $\hat{y}-y$ and then square it we are actually going to get a number bigger than 0.
We can see that what we actually count by the difference $\hat{y}-y$ is the height from the predicted value to the actual value.
When $w=0$ this is how it would look:

\begin{align*}
  \includegraphics[width=1.2\textwidth]{machine-learning/andrew_ng_intro_to_ml/cost_function_0.png}
\end{align*}

We see that in this case since the slope of the line is $0$ and it has a y-intercept of 0, it's just going through the x-axis.
Obviosuly we could have had negative values for $w$ and then the cost function would have ended up being more, but in conclusion the further is the distance between the predicted and actual values the more the cost function is going to be.
If we keep going with the values we can see that the graph between $w$ and $J(w)$ turns out to be a curve.

\begin{align*}
  \includegraphics[width=1.2\textwidth]{machine-learning/andrew_ng_intro_to_ml/cost_function_slope_curve.png}
\end{align*}

This curve shows the different values of the cost function with their slopes.
As we can see our goal was to have the smallest value of $J(w)$ and by our equation we concluded that when $J(w)=0$ will be $w=1$ which can be perfectly seen in the graph.

This is how you can use the cost function to identify the best fitting slope $w$.
Obviosuly we could have gotten further by having the y-intercept $b$ as a parameter but let's leave that to the next sections.

In summary, we have conducted that the goal of linear regression is to choose values for $w$ and $b$ that results the cost function $J$ to be the smallest value possible.
In order to find the best values for $w$ and $b$ we have to introduce the idea of gradient descent

\subsection{Gradient Descent}
Obviosuly our goal would be to find a systematic way of finding values for $w$ and $b$ that fits the data perfectly or results with the smallest possible cost $J$.
Gradient descent (GD) is an iterative first-order optimisation algorithm, used to find a local minimum/maximum of a given function. This method is commonly used in machine learning (ML) and deep learning (DL) to minimise a cost/loss function (e.g. in a linear regression).
Here is an overview of what we would want to achieve:
\begin{itemize}
  \item We have the function $J(w,b)$, gradient descent can be used to minimize not just the cost function but any given function.
  \item Our goal is to minimize it as min $J(w,b)$
  \item \textbf{Outline: } So this is how it works:
        \begin{enumerate}
          \item Start with some initial guesses for $w$ and $b$, it wouldn't matter that what would you start off with but it's a convention to start off with both $w=0$ and $b=0$
          \item Then what you will do is you will keep changing $w,b$ to reduce $J(w,b)$
          \item Until we settle at or near a local minimum which may be more than 1.
        \end{enumerate}
\end{itemize}

\subsection{Gradient Descent Mathematically}
So this is how it looks:
$$\displaystyle w=w-\alpha \frac{d}{dw}J(w,b) $$
Let's unpack the details of this equation. \\
First the equal notation $=$ in this case is an assignment operator. So we are going to take the value of $w-\alpha \frac{d}{dw}J(w,b)$ and store it in the variable $w$, this is thinking programatically
Because if we think matematically we claim that $w$ is equal to $w-\alpha \frac{d}{dw}J(w,b)$ which is not true, we are storing the value of $w-\alpha \frac{d}{dw}J(w,b)$ in the variable $w$. In conclusion the equal sign can be used for either assignment or truth assertion.
Let's unpack the different symbols in this equation:
\begin{itemize}
  \item $\alpha$ which is a greek letter, in this case the alpha is the \textbf{learning rate} which is a very small positive number such as 0.01, 0.001, 0.0001, between 0-1.
        $\alpha$ will determine how big of a step we take downhill on each iteration. By extension if its relatively big then we will take a big step downhill, if it's relatively small then we will take a small step downhill.
        Downhill means that we are trying to reduce the value of $J(w,b)$.
        We will go deeper in terms of choosing a good value for $\alpha$
  \item $\frac{d}{dw}J(w,b)$ is the derivative of the cost function $J(w,b)$ with respect to $w$. However we are going to talk about this in much more detail. You can think of the derivative as the direction and magnitude of the steps.
\end{itemize}

You have another parameter which is $b$ and you can update it in a similar way:
$$\displaystyle b=b-\alpha \frac{d}{db}J(w,b) $$

As a detail you want to make sure that you are updating $w$ and $b$ simultaneously, meaning that you want to update them at the same time. Also you are updating them from their old values, so you are not updating $w$ and $b$ from the original values but rather from their old values.


Here is the correct and incorrect way of updating $w$ and $b$:
\begin{align*}
  \includegraphics[width=1\textwidth]{machine-learning/andrew_ng_intro_to_ml/gradient_descent_implementation.png}
\end{align*}
\subsection{More deeply about gradient descent}
so here is the gradient descent algorithm:
$$ w=w-\alpha \frac{\partial L}{\partial w}$$
where $\alpha$ is the learning rate, and $\frac{\partial L}{\partial w}$  is the derivative term
and also for b:
$$ b=b-\alpha \frac{\partial}{\partial w}$$
where $\frac{\partial}{\partial b}$ is the derivative term \\

Just for the sake of simplicity let's assume that we are only dealing with $w$ and not $b$.
So our cost function would turn into $J(x)$ and our algorithm would change into:
$$ w=w-\alpha \frac{\partial J}{\partial w}$$

Let's look and talk about this diagram:
\begin{align*}
  \includegraphics[width=1\textwidth]{machine-learning/andrew_ng_intro_to_ml/gradient_descent_visualisation.png}
\end{align*}

Now as a remainder our goal is to find the $w$ where the $J(x)$ is the smallest. Gradient descent helps us find the local minimum of the cost function $J(x)$.
Looking at the first example we have started off with a random example then what the derivative does is it uses something called the tangent line to find the slope of the line at that point.
The tangent line is a line that touches the curve at that point. As we can see we are getting back 2 which means that it is a positive number.
We know that the learning rate $\alpha$ is a positive number, so looking into the subtraction its obvious that we are going to reduce the value of $w$.
By extension we are going backwards which proves the gradient descent functionality as we are getting closer to the local minimum.
Now let's look at the second example where we are getting a negative number and when we subtract a negative number we essentially are adding a positive number which is going to increase the value of $w$, so we are going to go forward, which again proves the gradient descent as we are getting closer to the local minimum.

In summary the derivative term will use the tangent line to find the slope of the curve at a given point, then we use that slope to find the direction of the step that gets us closer to the local minimum. Now the last thing that we don't really understand is the learning rate $\alpha$.

\subsection{Learning rate}
The value of $\alpha$ has a huge impact on the efficiency of the gradient descent. If it is chosen poorly then the gradient descent might not work at all.

To understand the impact and the significance of the learning rate let's look at what happens when it's either too big or when it's too small.

\begin{align*}
  \includegraphics[width=1\textwidth]{machine-learning/andrew_ng_intro_to_ml/learning_rate_big_small.png}
\end{align*}

Now if the learning rate is too small then the gradient descent will take a long time to converge, meaning that it will take a long time to find the local minimum.
However we will still find the minimum, it will just take a long time.
When the learning rate is too big then the gradient descent might not converge at all, meaning that it might not find the local minimum. This can happen when the learning rate is too big and it goes over the local minimum and it stucks in a loop.

Now one thing to mention is what happens when the gradient descent reaches the local minimum.
Let's look at this diagram:
\begin{align*}
  \includegraphics[width=1\textwidth]{machine-learning/andrew_ng_intro_to_ml/local_minimum_validation.png}
\end{align*}

As you can see when the gradient descent reaches the local minimum the derivative will be 0, so when we multiply it by the learning rate $\alpha$ it will be 0, and when subtractng 0 from $w$ it will be the same value.
In conclusion when we reach a local minimum further gradient descent steps will do absolutely nothing, so we can stop the gradient descent when we reach a local minimum.

Let's look at another concept that how gradient descent can reac local minimum with fixed learning rate.
\begin{align*}
  \includegraphics[width=1\textwidth]{machine-learning/andrew_ng_intro_to_ml/local_minimum_fixed_learning_rate.png}
\end{align*}

As we can see when we take the first step, the slope of the tangent line at that point is really big, therefore we are taking a big step.
As we are taking the steps the slope of the tangent line is getting smaller and smaller, therefore we are taking smaller and smaller steps.
When we reach the local minimum the slope of the tangent line is 0, therefore we are not taking any steps.
This explains that whenever we are approaching the local minimum the steps are getting smaller and smaller, because the slope is smaller, then the derivative is smaller and $w$ is smaller so we are taking a smaller step.
In conclusion the gradient descent can reach the local minimum without decreasing the learning rate $\alpha$.

\subsection{Put it all together - Gradient Descent for Linear Regression}
Now let's put it all together and see how we can use gradient descent to find the best fitting line for our data-set.
Recall that we have the following model: $$ f_{w,b}(x) = wx + b $$
We have the following cost function: $$ J_{(w,b)}=\frac{1}{2m}\sum_{i=0}^{m}\ (f_w,b(x^{(i)})-y^{(i)})^2 $$
And we have the following gradient descent algorithm:
$$ w=w-\alpha \frac{\partial}{\partial w}J(w,b)$$
$$ b=b-\alpha \frac{\partial}{\partial b}J(w,b)$$


\subsection{Calculate the derivative terms}

We have this derivative with respect to $w$:
$$ \frac{\partial}{\partial w}J(w,b)$$
We start by plugging in the definition of $J(w,b)$:
$$ \frac{\partial}{\partial w}J(w,b)=\frac{\partial}{\partial w}\frac{1}{2m}\sum_{i=0}^{m}\ (f_w,b(x^{(i)})-y^{(i)})^2$$
Remember that $f_w,b(x^{(i)})$ is the same as $wx^{(i)}+b$ so we can substitute that in:
$$ \frac{\partial}{\partial w}J(w,b)=\frac{\partial}{\partial w}\frac{1}{2m}\sum_{i=0}^{m}\ (wx^{(i)}+b-y^{(i)})^2$$
We know that the derivative is equal to will be equal to $2x^{(i)}$ so we can substitute that in:
$$ \frac{\partial}{\partial w}J(w,b)=\frac{1}{m}\sum_{i=0}^{m}\ (wx^{(i)}+b-y^{(i)})x^{(i)}$$
Let's do the same thing for $b$:
$$ \frac{\partial}{\partial b}J(w,b)=\frac{\partial}{\partial b}\frac{1}{2m}\sum_{i=0}^{m}\ (f_w,b(x^{(i)})-y^{(i)})^2$$
and we can substitute $f_w,b(x^{(i)})$ with $wx^{(i)}+b$:
$$ \frac{\partial}{\partial b}J(w,b)=\frac{\partial}{\partial b}\frac{1}{2m}\sum_{i=0}^{m}\ (wx^{(i)}+b-y^{(i)})^2$$
We know that the derivative is equal to will be equal to $2$ so we can substitute that in:
$$ \frac{\partial}{\partial b}J(w,b)=\frac{1}{m}\sum_{i=0}^{m}\ (wx^{(i)}+b-y^{(i)})$$

Now that we know this we can apply them to the gradient descent algorithm:
repeat until convergence \{
$$ w=w-\alpha \frac{1}{m}\sum_{i=0}^{m}\ (wx^{(i)}+b-y^{(i)})x^{(i)}$$
$$ b=b-\alpha \frac{1}{m}\sum_{i=0}^{m}\ (wx^{(i)}+b-y^{(i)})$$
\}

The model representation shows how these algorithms are made up in code.

\subsection{Multiple Features}

So far we have only looked at the case where we have one input feature, such as the size of the house. However in real life we will have multiple input features, such as the size of the house, the number of bedrooms, the number of floors, etc...
\begin{align*}
  \includegraphics[width=1.1\textwidth]{machine-learning/andrew_ng_intro_to_ml/multiple_features.png}
\end{align*}
In the original version of linear regression, you had a single feature x, the size of the house and you're able to predict y, 
the price of the house. The model was fwb of x equals wx plus b. But now, what if you did not only have the size of the house as a 
feature with which to try to predict the price, but if you also knew the number of bedrooms, the number of floors and the age of the 
home in years. It seems like this would give you a lot more information with which to predict the price. To introduce a little bit of
 new notation, we're going to use the variables $X_1, X_2, X_3 and X_4$, to denote the four features. For simplicity, let's introduce 
 a little bit more notation. We'll write X subscript j or sometimes I'll just say for short, X sub j, to represent the list of 
 features. Here, j will go from one to four, because we have four features. I'm going to use lowercase n to denote the total number 
 of features, so in this example, n is equal to 4. As before, we'll use X superscript i to denote the ith training example. 
 Here X superscript i is actually going to be a list of four numbers, or sometimes we'll call this a vector that includes all the 
 features of the ith training example. As a concrete example, X superscript in parentheses 2, will be a vector of the features for 
 the second training example, so it will equal to this 1416, 3, 2 and 40 and technically, I'm writing these numbers in a row, so 
 sometimes this is called a row vector rather than a column vector. But if you don't know what the difference is, don't worry about 
 it, it's not that important for this purpose. To refer to a specific feature in the ith training example, I will write X superscript 
 i, subscript j, so for example, X superscript 2 subscript 3 will be the value of the third feature, that is the number of floors in 
 the second training example and so that's going to be equal to 2. Sometimes in order to emphasize that this$X^2$ is not a number but 
 is actually a list of numbers that is a vector, we'll draw an arrow on top of that just to visually 
 show that is a vector and over here as well, but you don't have to draw this arrow in your notation. 
 You can think of the arrow as an optional signifier. They're sometimes used just to emphasize that this is a vector 
 and not a number. Now that we have multiple features, let's take a look at what a model would look like.

 \begin{align*}
  \includegraphics[width=1.1\textwidth]{machine-learning/andrew_ng_intro_to_ml/model_representation.png}
\end{align*}

The definition of model with n features is going to be $f_w,b(x)=w_1x_1+w_2x_2+...+w_nx_n+b$.
We can make this easier by defining $w$ as a vector: 
$$\vec{w}=[w_1,w_2,...,w_n]$$
$w$ and $b$ are the parameters of the model. 
We can also define $x$ as a vector:
$$\vec{x}=[x_1,x_2,...,x_n]$$

Therefore we can rewrite the model as follows:
$$f_w,b(\vec{x})=\vec{w}\cdot\vec{x}+b$$
where $\vec{w}\cdot\vec{x}$ is the dot product of the two vectors.
A linear regression with multiple features is called a multiple linear regression.

\subsection{Gradient Descent for Multiple Features}

Now let's look at how we can use gradient descent for multiple features.
\begin{align*}
  \includegraphics[width=1.1\textwidth]{machine-learning/andrew_ng_intro_to_ml/gradient_descent_multiple_regression.png}
\end{align*} \break